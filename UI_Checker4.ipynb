{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\laiyy\\anaconda3\\lib\\site-packages (2.10.0)\n",
      "Requirement already satisfied: tensorflow-cpu in c:\\users\\laiyy\\anaconda3\\lib\\site-packages (2.10.1)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\laiyy\\anaconda3\\lib\\site-packages (4.7.0.72)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\laiyy\\anaconda3\\lib\\site-packages (3.7.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\laiyy\\anaconda3\\lib\\site-packages (1.2.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\laiyy\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\laiyy\\anaconda3\\lib\\site-packages (from tensorflow) (1.42.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\laiyy\\anaconda3\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\laiyy\\anaconda3\\lib\\site-packages (from tensorflow) (1.3.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\laiyy\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\laiyy\\anaconda3\\lib\\site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\laiyy\\anaconda3\\lib\\site-packages (from tensorflow) (1.23.5)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\laiyy\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\laiyy\\anaconda3\\lib\\site-packages (from tensorflow) (4.4.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\laiyy\\anaconda3\\lib\\site-packages (from tensorflow) (0.31.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\laiyy\\anaconda3\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\laiyy\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in c:\\users\\laiyy\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\laiyy\\anaconda3\\lib\\site-packages (from tensorflow) (23.3.3)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in c:\\users\\laiyy\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\laiyy\\anaconda3\\lib\\site-packages (from tensorflow) (16.0.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\laiyy\\anaconda3\\lib\\site-packages (from tensorflow) (3.19.6)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in c:\\users\\laiyy\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\laiyy\\anaconda3\\lib\\site-packages (from tensorflow) (2.2.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\laiyy\\anaconda3\\lib\\site-packages (from tensorflow) (22.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\laiyy\\anaconda3\\lib\\site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\laiyy\\anaconda3\\lib\\site-packages (from tensorflow) (65.6.3)\n",
      "Requirement already satisfied: tensorflow-intel==2.10.1 in c:\\users\\laiyy\\anaconda3\\lib\\site-packages (from tensorflow-cpu) (2.10.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\laiyy\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\laiyy\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\laiyy\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\laiyy\\anaconda3\\lib\\site-packages (from matplotlib) (1.0.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\laiyy\\anaconda3\\lib\\site-packages (from matplotlib) (9.4.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\laiyy\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\laiyy\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\laiyy\\anaconda3\\lib\\site-packages (from scikit-learn) (1.10.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\laiyy\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\laiyy\\anaconda3\\lib\\site-packages (from scikit-learn) (1.1.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\laiyy\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\laiyy\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\laiyy\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\laiyy\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\laiyy\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\laiyy\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.6.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\laiyy\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.4.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\laiyy\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\laiyy\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\laiyy\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\laiyy\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\laiyy\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\laiyy\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\laiyy\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\laiyy\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\laiyy\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (3.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\laiyy\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\laiyy\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\laiyy\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow tensorflow-cpu opencv-python matplotlib scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import KFold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set GPU memory growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define data directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir_good = 'Good_UI'\n",
    "data_dir_bad = 'Bad_UI'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set image parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (256, 256)\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.experimental.preprocessing.Rescaling(1./255),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomRotation(0.1),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create ImageDataGenerator for loading and augmenting images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(preprocessing_function=data_augmentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and prepare the good image dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images belonging to 0 classes.\n"
     ]
    }
   ],
   "source": [
    "good_dataset = datagen.flow_from_directory(\n",
    "    data_dir_good,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and prepare the bad image dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images belonging to 0 classes.\n"
     ]
    }
   ],
   "source": [
    "bad_dataset = datagen.flow_from_directory(\n",
    "    data_dir_bad,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine both datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\laiyy\\AppData\\Local\\Temp\\ipykernel_9204\\352089868.py:1: sample_from_datasets_v2 (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.sample_from_datasets(...)`.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DirectoryIterator' object has no attribute 'element_spec'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m combined_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperimental\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_from_datasets\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mgood_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbad_dataset\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:357\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecated_wrapper.<locals>.new_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    349\u001b[0m       _PRINTED_WARNING[func] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    350\u001b[0m     logging\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    351\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFrom \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m (from \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) is deprecated and will be removed \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    352\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInstructions for updating:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    355\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124min a future version\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m date \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m date),\n\u001b[0;32m    356\u001b[0m         instructions)\n\u001b[1;32m--> 357\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\interleave_ops.py:148\u001b[0m, in \u001b[0;36msample_from_datasets_v2\u001b[1;34m(datasets, weights, seed, stop_on_empty_dataset)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;129m@deprecation\u001b[39m\u001b[38;5;241m.\u001b[39mdeprecated(\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     90\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse `tf.data.Dataset.sample_from_datasets(...)`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     91\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata.experimental.sample_from_datasets\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     94\u001b[0m                             seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     95\u001b[0m                             stop_on_empty_dataset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m     96\u001b[0m   \u001b[38;5;124;03m\"\"\"Samples elements at random from the datasets in `datasets`.\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \n\u001b[0;32m     98\u001b[0m \u001b[38;5;124;03m  Creates a dataset by interleaving elements of `datasets` with `weight[i]`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;124;03m      - If `weights` is specified and does not match the length of `datasets`.\u001b[39;00m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 148\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_from_datasets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatasets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[43m      \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[43m      \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[43m      \u001b[49m\u001b[43mstop_on_empty_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop_on_empty_dataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:3564\u001b[0m, in \u001b[0;36mDatasetV2.sample_from_datasets\u001b[1;34m(datasets, weights, seed, stop_on_empty_dataset)\u001b[0m\n\u001b[0;32m   3558\u001b[0m   logits_and_seeds \u001b[38;5;241m=\u001b[39m Dataset\u001b[38;5;241m.\u001b[39mzip((logits_ds, RandomDataset(seed)\u001b[38;5;241m.\u001b[39mbatch(\u001b[38;5;241m2\u001b[39m)))\n\u001b[0;32m   3559\u001b[0m   selector_input \u001b[38;5;241m=\u001b[39m MapDataset(\n\u001b[0;32m   3560\u001b[0m       logits_and_seeds,\n\u001b[0;32m   3561\u001b[0m       select_dataset_varying_logits,\n\u001b[0;32m   3562\u001b[0m       use_inter_op_parallelism\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m-> 3564\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_DirectedInterleaveDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mselector_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatasets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3565\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mstop_on_empty_dataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:6391\u001b[0m, in \u001b[0;36m_DirectedInterleaveDataset.__init__\u001b[1;34m(self, selector_input, data_inputs, stop_on_empty_dataset)\u001b[0m\n\u001b[0;32m   6388\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(data_inputs)\n\u001b[0;32m   6389\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop_on_empty_dataset \u001b[38;5;241m=\u001b[39m stop_on_empty_dataset\n\u001b[1;32m-> 6391\u001b[0m spec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_inputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43melement_spec\u001b[49m\n\u001b[0;32m   6392\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, data_input \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_inputs[\u001b[38;5;241m1\u001b[39m:]):\n\u001b[0;32m   6393\u001b[0m   \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcommon_supertype\u001b[39m(a, b):\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DirectoryIterator' object has no attribute 'element_spec'"
     ]
    }
   ],
   "source": [
    "combined_dataset = tf.data.experimental.sample_from_datasets([good_dataset, bad_dataset])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform cross-validation using K-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5  # Number of folds\n",
    "num_samples = len(combined_dataset)\n",
    "fold_indices = list(range(num_samples))\n",
    "kfold = KFold(n_splits=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold, (train_indices, val_indices) in enumerate(kfold.split(fold_indices)):\n",
    "print(f\"Fold: {fold + 1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # Split data into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = combined_dataset.take(train_indices)\n",
    "val_data = combined_dataset.skip(train_indices).take(val_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define and compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(256, 256, 3)),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        tf.keras.layers.Conv2D(16, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(256, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_data, epochs=20, validation_data=val_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(val_data)\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
